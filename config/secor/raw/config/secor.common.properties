cloud.service=azure
hive.table.prefix=
kafka.client.className=com.pinterest.secor.common.SecorKafkaClient
kafka.consumer.auto.offset.reset=smallest
kafka.consumer.timeout.ms=10000
kafka.dual.commit.enabled=true
kafka.fetch.max.bytes=
kafka.fetch.message.max.bytes=5242880
kafka.fetch.min.bytes=
kafka.fetch.wait.max.ms=
kafka.message.iterator.className=com.pinterest.secor.reader.SecorKafkaMessageIterator
kafka.message.timestamp.className=com.pinterest.secor.timestamp.Kafka10MessageTimestamp
kafka.new.consumer.auto.offset.reset=earliest
kafka.new.consumer.isolation.level=
kafka.new.consumer.max.poll.interval.ms=
kafka.new.consumer.max.poll.records=
kafka.new.consumer.partition.assignment.strategy.class=
kafka.new.consumer.poll.timeout.seconds=10
kafka.new.consumer.request.timeout.ms=10000
kafka.new.consumer.sasl.client.callback.handler.class=
kafka.new.consumer.sasl.jaas.config=
kafka.new.consumer.sasl.kerberos.service.name=
kafka.new.consumer.sasl.login.callback.handler.class=
kafka.new.consumer.sasl.login.class=
kafka.new.consumer.sasl.mechanism=
kafka.new.consumer.security.protocol=
kafka.new.consumer.ssl.enabled.protocols=
kafka.new.consumer.ssl.key.password=
kafka.new.consumer.ssl.keystore.location=
kafka.new.consumer.ssl.keystore.password=
kafka.new.consumer.ssl.keystore.type=
kafka.new.consumer.ssl.protocol=
kafka.new.consumer.ssl.provider=
kafka.new.consumer.ssl.truststore.location=
kafka.new.consumer.ssl.truststore.password=
kafka.new.consumer.ssl.truststore.type=
kafka.new.consumer.topic.list=prod.quess.raw
kafka.offsets.storage=kafka
kafka.partition.assignment.strategy=range
kafka.rebalance.backoff.ms=
kafka.rebalance.max.retries=
kafka.socket.receive.buffer.bytes=
kafka.useTimestamp=false
kafka.zookeeper.path=/
message.fallback.timestamp.name=timestamp
message.timestamp.id=1
message.timestamp.input.pattern=yyyy-MM-dd
message.timestamp.name.separator=
message.timestamp.name=timestamp
message.timestamp.required=true
message.timestamp.type=i64
monitoring.blacklist.topics=
monitoring.interval.seconds=0
monitoring.prefix=secor
parquet.block.size=134217728
parquet.enable.dictionary=true
parquet.page.size=1048576
parquet.validation=false
partitioner.finalizer.delay.seconds=3600
partitioner.granularity.date.format=yyyy-MM-dd
partitioner.granularity.date.prefix=dt=
partitioner.granularity.hour.format=HH
partitioner.granularity.hour.prefix=hr=
partitioner.granularity.hour=false
partitioner.granularity.minute.format=mm
partitioner.granularity.minute.prefix=min=
partitioner.granularity.minute=false
qubole.api.token=
secor.compression.codec=org.apache.hadoop.io.compress.GzipCodec
secor.consumer.threads=7
secor.enable.qubole=true
secor.file.age.youngest=true
secor.file.extension=.gz
secor.file.reader.Delimiter=\n
secor.file.reader.writer.factory=com.pinterest.secor.io.impl.DelimitedTextFileReaderWriterFactory
secor.file.writer.Delimiter=\n
secor.generation=1
secor.kafka.topic_blacklist=
secor.kafka.topic_filter=prod.quess.raw
secor.kafka.upload_at_minute_mark.topic_filter=
secor.local.log.delete.age.hours=-1
secor.max.message.size.bytes=100000
secor.message.timezone=UTC
secor.message.transformer.class=com.pinterest.secor.transformer.IdentityMessageTransformer
secor.messages.per.second=10000
secor.monitoring.metrics.collector.class=com.pinterest.secor.monitoring.OstrichMetricCollector
secor.offsets.per.partition=10000000
secor.offsets.prefix=offset=
secor.orc.message.schema.*=struct<a:int\,b:int\,c:struct<d:int\,e:string>\,f:array<string>\,g:int>
secor.orc.schema.provider=com.pinterest.secor.util.orc.schema.DefaultORCSchemaProvider
secor.parser.timezone=Asia/Kolkata
secor.qubole.timeout.ms=300000
secor.thrift.message.class.*=
secor.thrift.protocol.class=
secor.topic_partition.forget.seconds=600
secor.upload.deterministic=false
secor.upload.minute_mark=0
secor.upload.on.shutdown=false
secor.upload.secor.upload.last.seen.offset=false
secor.zookeeper.path=/
statsd.hostport=
statsd.prefixWithConsumerGroup=true
tsdb.hostport=
zookeeper.session.timeout.ms=3000
zookeeper.sync.time.ms=200
